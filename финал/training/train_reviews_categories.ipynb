{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":118375,"status":"ok","timestamp":1714725751196,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"CYRomC9w6k3B"},"outputs":[],"source":["%%capture\n","%pip install pymorphy3 focal-loss-torch"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10636,"status":"ok","timestamp":1714725761829,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"JOREmrOuUyAu"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import pymorphy3\n","import warnings\n","\n","from dateutil import parser\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from sklearn.metrics import f1_score, roc_auc_score\n","from tqdm import tqdm\n","from transformers import AutoModel, AutoTokenizer\n","from collections import defaultdict, OrderedDict\n","from focal_loss.focal_loss import FocalLoss\n","\n","def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","    return torch.Generator().manual_seed(seed)\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17903,"status":"ok","timestamp":1714725835456,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"4AFgx9pmn1mR","outputId":"93117a9a-604d-4057-8d37-2c20a0a9081b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1QWQuBUa7I69FmBvgtIrnoya4ebvjuNlI\n","From (redirected): https://drive.google.com/uc?id=1QWQuBUa7I69FmBvgtIrnoya4ebvjuNlI\u0026confirm=t\u0026uuid=ab8f07cf-d95c-4740-a82c-7bd5e12992f9\n","To: /content/model_f1m_0.530.pt\n","100% 714M/714M [00:15\u003c00:00, 44.7MB/s]\n"]}],"source":["!gdown 1QWQuBUa7I69FmBvgtIrnoya4ebvjuNlI\n","!gdown 1AgftFgsgDfnFoLL-G9mj_-ShfSPQi0lI"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1030,"status":"ok","timestamp":1714726390999,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"rbD7a5yGYocc"},"outputs":[],"source":["# data = pd.read_parquet(\"/kaggle/input/rew-cat/reviews_categories.parquet\")\n","data = pd.read_parquet(\"/content/reviews_categories.parquet\")\n","data = data.drop_duplicates(\"text\")\n","\n","# выбрасываем 1000 наблюдений 0 класса\n","data = data.sort_values(\"label\", ascending=True)[10000:]\n","\n","#сэмплим одинаковое кол-во по минимальному классу\n","min_count = data[\"label\"].value_counts().min()\n","# data = data.groupby(\"label\").sample(n=min_count)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1714726395650,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"HAHYeRjSbM9F"},"outputs":[],"source":["class catDataset(Dataset):\n","  def __init__(self, data, tokenizer):\n","    self.text = data[\"text\"]\n","    self.label = data[\"label\"]\n","    self.tokenizer = tokenizer\n","\n","  def __getitem__(self, x):\n","    return self.tokenizer.encode(self.text.iloc[x], truncation=\"longest_first\", max_length=512), self.label.iloc[x]\n","\n","  def __len__(self):\n","    return len(self.text)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714726867415,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"4P2dg9vyVb_z"},"outputs":[],"source":["class BertClassifierModel(nn.Module):\n","    def __init__(self, hidden_dim, bert_model, n_classes):\n","        super().__init__()\n","        self.bert = bert_model\n","        self.linear = nn.Sequential(OrderedDict([\n","            (\"ln1\", nn.Linear(768, hidden_dim)),\n","            (\"act\", nn.LeakyReLU()),\n","            (\"ln2\", nn.Linear(hidden_dim, n_classes)),\n","            # (\"act1\", nn.LeakyReLU()),\n","            # (\"ln3\", nn.Linear(hidden_dim, n_classes))\n","        ]))\n","        # self.linear = nn.Linear(768, n_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","      x = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n","      x = self.linear(x)\n","      return x\n","\n","\n","class BertClassifier:\n","\n","  def __init__(self, seed, device, model_path):\n","    self.g = seed_everything(seed)\n","    self.device = device\n","    if isinstance(device, str):\n","      self.device = torch.device(device)\n","    self.model_path = model_path\n","\n","  def init_data(self, data, dataset_class, batch_size, splits=[0.9, 0.1]):\n","\n","    def collate(data):\n","      # print(data)\n","      max_len = len(max(data, key=lambda x: len(x[0]))[0])\n","      # print(max_len)\n","      input_ids = [i[0] + [0] * (max_len - len(i[0])) for i in data]\n","      attention_mask = [[1] * len(i[0]) + [0] * (max_len - len(i[0])) for i in data]\n","      target = [i[1] for i in data]\n","\n","      return input_ids, attention_mask, target\n","\n","    dataset = dataset_class(data, AutoTokenizer.from_pretrained(self.model_path))\n","\n","    train, test = random_split(dataset, lengths=splits)\n","\n","    self.train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate, num_workers=2)\n","    self.val_loader = DataLoader(test, batch_size=batch_size, shuffle=False,  collate_fn=collate, num_workers=2)\n","\n","  def init_model(self, hidden_dim=128, n_classes=10):\n","    model = AutoModel.from_pretrained(self.model_path)\n","    model = BertClassifierModel(hidden_dim=hidden_dim, bert_model=model, n_classes=n_classes)\n","    model.eval()\n","    for p in model.parameters(): p.requires_grad = False\n","    for p in model.bert.pooler.parameters(): p.requires_grad = True\n","    for p in model.linear.parameters(): p.requires_grad = True\n","    model = model.to(self.device)\n","    self.model = model\n","\n","  def load_model(self, model_path, map_location=\"cuda\"):\n","\n","    self.model.load_state_dict(torch.load(model_path, map_location=map_location))\n","\n","    self.model.eval()\n","    for p in self.model.parameters(): p.requires_grad = False\n","    for p in self.model.bert.pooler.parameters(): p.requires_grad = True\n","    for p in self.model.linear.parameters(): p.requires_grad = True\n","    self.model = self.model.to(self.device)\n","\n","\n","  def train_one_epoch(self, loss_fn, optimizer, task):\n","    lossi = []\n","    f1_i = []\n","    roc_auc_i = []\n","\n","    stream = tqdm(self.train_loader)\n","\n","    self.model.train()\n","    for input_ids, attention_mask, y_batch in stream:\n","        input_ids = torch.tensor(input_ids).to(self.device, non_blocking=True)\n","        attention_mask = torch.tensor(attention_mask).to(self.device, non_blocking=True)\n","        y_batch = torch.tensor(y_batch).to(self.device, non_blocking=True)\n","        logits = self.model(input_ids, attention_mask)\n","        if task == \"binary\": probs = torch.sigmoid(logits)\n","        else: probs = torch.nn.functional.softmax(logits, dim=1)\n","        loss = loss_fn(probs, y_batch)\n","        lossi.append(loss.item())\n","\n","        f1_i.append(f1_score(y_batch.cpu(), probs.argmax(axis=1).cpu(), average=\"binary\" if task == \"binary\" else \"micro\"))\n","        if all(y_batch) or (not any(y_batch)) or task != \"binary\":\n","            roc_auc_i.append(0)\n","        else:\n","            roc_auc_i.append(roc_auc_score(y_batch.cpu(), probs.argmax(axis=1).cpu()))\n","\n","        stream.set_description(f\"train: loss: {np.mean(lossi)}, f1: {np.mean(f1_i)}, roc_auc: {np.mean(roc_auc_i)}\")\n","\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","  def validate_one_epoch(self, loss_fn, task):\n","    lossi = []\n","    f1_i = []\n","    roc_auc_i = []\n","\n","    stream = tqdm(self.val_loader)\n","\n","    self.model.eval()\n","\n","    with torch.no_grad():\n","      for input_ids, attention_mask, y_batch in stream:\n","        input_ids = torch.tensor(input_ids).to(self.device, non_blocking=True)\n","        attention_mask = torch.tensor(attention_mask).to(self.device, non_blocking=True)\n","        y_batch = torch.tensor(y_batch).to(self.device, non_blocking=True)\n","        logits = self.model(input_ids, attention_mask)\n","        if task == \"binary\": probs = torch.sigmoid(logits)\n","        else: probs = torch.nn.functional.softmax(logits, dim=1)\n","        loss = loss_fn(probs, y_batch)\n","        lossi.append(loss.item())\n","\n","        f1_i.append(f1_score(y_batch.cpu(), probs.argmax(axis=1).cpu(), average=\"binary\" if task == \"binary\" else \"micro\"))\n","#         print(y_batch, all(y_batch), any(y_batch))\n","        if all(y_batch) or (not any(y_batch)) or task != \"binary\":\n","            roc_auc_i.append(0)\n","        else:\n","            roc_auc_i.append(roc_auc_score(y_batch.cpu(), probs.argmax(axis=1).cpu()))\n","\n","        stream.set_description(f\"validation: loss: {np.mean(lossi)}, f1: {np.mean(f1_i)}, roc_auc: {np.mean(roc_auc_i)}\")\n","#         stream.set_description(f\"validation: loss: {loss.item()}, f1: {f1_i[-1]}\")\n","    return np.mean(f1_i)\n","\n","  def train(self, num_epochs, lr, gamma, task=\"binary\", best_f1=0, checkpoint=None):\n","\n","      loss_fn = nn.BCELoss() if task == \"binary\" else FocalLoss(gamma=gamma)\n","      optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n","      for epoch in range(num_epochs):\n","        print(f\"epoch {epoch} started\")\n","        self.train_one_epoch(loss_fn, optimizer, task)\n","        val_f1 = self.validate_one_epoch(loss_fn, task)\n","        if best_f1 \u003c val_f1:\n","            best_f1 = val_f1\n","            self.best_model = self.model\n","            if checkpoint != None:\n","                torch.save(self.model.state_dict(), checkpoint + f\"/model_f1m_{val_f1:.3f}.pt\")\n","      print(f\"train finished with best f1 micro={best_f1}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1714726178570,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"LEN_7jukIi5A"},"outputs":[],"source":["# %mkdir /kaggle/working/checkpoint\n","%mkdir /content/checkpoint"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1714726871551,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"C33lEcn14utO"},"outputs":[],"source":["worker = BertClassifier(seed=42, device=\"cuda\", model_path=\"ai-forever/ruBert-base\")"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":950,"status":"ok","timestamp":1714726872747,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"JoRIQ7hLGUVi"},"outputs":[],"source":["worker.init_data(data, catDataset, 16)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DEae_AGGlbSB"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3674,"status":"ok","timestamp":1714726877460,"user":{"displayName":"ISY640","userId":"14578547707035782428"},"user_tz":-180},"id":"yolqUSiTdrRN"},"outputs":[],"source":["worker.init_model(n_classes=8, hidden_dim=128)\n","worker.load_model(\"/content/model_f1m_0.530.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mWQZlen1XVXu"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch 0 started\n"]},{"name":"stderr","output_type":"stream","text":["train: loss: 1.2089808293091995, f1: 0.48759266886326197, roc_auc: 0.0: 100%|██████████| 2428/2428 [14:35\u003c00:00,  2.77it/s]\n","validation: loss: 1.183378301947205, f1: 0.5018728956228956, roc_auc: 0.0: 100%|██████████| 270/270 [01:31\u003c00:00,  2.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 1 started\n"]},{"name":"stderr","output_type":"stream","text":["train: loss: 1.1864038924065217, f1: 0.4984709637561779, roc_auc: 0.0: 100%|██████████| 2428/2428 [14:45\u003c00:00,  2.74it/s]\n","validation: loss: 1.1692565792136722, f1: 0.506060606060606, roc_auc: 0.0: 100%|██████████| 270/270 [01:31\u003c00:00,  2.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 2 started\n"]},{"name":"stderr","output_type":"stream","text":["train: loss: 1.1778337048885261, f1: 0.5034287479406919, roc_auc: 0.0: 100%|██████████| 2428/2428 [14:42\u003c00:00,  2.75it/s]\n","validation: loss: 1.1615303860770332, f1: 0.5112584175084175, roc_auc: 0.0: 100%|██████████| 270/270 [01:31\u003c00:00,  2.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 3 started\n"]},{"name":"stderr","output_type":"stream","text":["train: loss: 1.1681110966686754, f1: 0.50667215815486, roc_auc: 0.0: 100%|██████████| 2428/2428 [15:13\u003c00:00,  2.66it/s]\n","validation: loss: 1.155024489208504, f1: 0.511026936026936, roc_auc: 0.0: 100%|██████████| 270/270 [01:35\u003c00:00,  2.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 4 started\n"]},{"name":"stderr","output_type":"stream","text":["train: loss: 1.1600566268261812, f1: 0.5080673393739704, roc_auc: 0.0: 100%|██████████| 2428/2428 [14:49\u003c00:00,  2.73it/s]\n","validation: loss: 1.1477923179114307, f1: 0.517276936026936, roc_auc: 0.0: 100%|██████████| 270/270 [01:31\u003c00:00,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["train finished with best f1 micro=0.53\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# torch.cuda.empty_cache()\n","worker.train(5, gamma=0.5, lr=2e-5 / 3, task=\"multiclass\", checkpoint=\"/content/checkpoint\", best_f1=0.53)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKqzyrwCnJ4E"},"outputs":[],"source":["%cd /kaggle/working/checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pq5h2mDMnJ4E"},"outputs":[],"source":["from IPython.display import FileLink\n","from glob import glob\n","\n","FileLink(sorted(glob(\"/kaggle/working/checkpoint/*\"))[-1].replace(\"/kaggle/working/checkpoint/\", \"\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5_aXTFXYocs"},"outputs":[],"source":["# loss = nn.CrossEntropyLoss()\n","for input_ids, attention_mask, y_batch in worker.train_loader:\n","    for in_id in input_ids:\n","        print(tokenizer.decode(in_id))\n","#     input_ids = torch.tensor(input_ids).to(worker.device)\n","# #     print(input_ids)\n","#     attention_mask = torch.tensor(attention_mask).to(worker.device)\n","# #     print(attention_mask)\n","#     y_batch = torch.tensor(y_batch).to(worker.device)\n","#     print(y_batch)\n","#     print(worker.model(input_ids=input_ids, attention_mask=attention_mask).shape)\n","#     probs = torch.nn.functional.softmax(worker.model(input_ids=input_ids, attention_mask=attention_mask), dim=1)\n","#     print(y_batch)\n","# #     break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsHsB2vDeQGI"},"outputs":[],"source":["data[\"info\"].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjElcolWYocu"},"outputs":[],"source":["y_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xr9hbQ1WsV-S"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4917185,"sourceId":8280022,"sourceType":"datasetVersion"},{"datasetId":4917582,"sourceId":8280548,"sourceType":"datasetVersion"},{"datasetId":4918897,"sourceId":8282353,"sourceType":"datasetVersion"},{"datasetId":4920169,"sourceId":8284008,"sourceType":"datasetVersion"},{"datasetId":4927125,"sourceId":8293723,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}